{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ec8682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.cosmos import CosmosClient, PartitionKey\n",
    "\n",
    "# Set up environment variables for Azure OpenAI\n",
    "oai_client = AzureOpenAI(\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'), \n",
    "    api_version = os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    ")\n",
    "\n",
    "# Set up environment variables for Azure OpenAI Embeddings\n",
    "emb_client = AzureOpenAI(\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),  \n",
    "    api_version = os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_EMBEDDINGS_ENDPOINT')\n",
    ")\n",
    "\n",
    "# Set up environment variables for Azure Cosmos DB\n",
    "url = os.getenv('COSMOS_DB_ENDPOINT')\n",
    "key = os.getenv('COSMOS_DB_KEY')\n",
    "db_client = CosmosClient(url, credential=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163e247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings for text chunks\n",
    "def create_embeddings(text, model=os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")):\n",
    "    # Create embeddings for each document chunk\n",
    "    embeddings = emb_client.embeddings.create(input = text, model=model).data[0].embedding\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd496ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from Azure Cosmos DB\n",
    "container = db_client.get_database_client('interview-assistant').get_container_client('chunks')\n",
    "items = list(container.read_all_items())\n",
    "flattened_df = pd.DataFrame(items)\n",
    "\n",
    "# Create the search index\n",
    "X = np.vstack(flattened_df['embedding'].to_numpy())\n",
    "nbrs = NearestNeighbors(n_neighbors=8, algorithm='auto').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34aa6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle user input and generate a response\n",
    "def chatbot(user_input, neighbors=8):\n",
    "    \"\"\"\n",
    "    Handles user input, retrieves relevant documents, and generates a response using Azure OpenAI.\n",
    "    Args:\n",
    "        user_input (str): The user's question or input.\n",
    "    Returns:\n",
    "        str: The generated response from the AI assistant.\n",
    "    \"\"\"\n",
    "    # Convert the question to a query vector\n",
    "    query_vector = create_embeddings(user_input)\n",
    "\n",
    "    # Find the most similar documents\n",
    "    _, indices = nbrs.kneighbors([query_vector], n_neighbors=neighbors)\n",
    "\n",
    "    # Use a set to avoid duplicates\n",
    "    indices_set = set(indices[0])  \n",
    "\n",
    "    # Retrieve text chunks\n",
    "    context_chunks = [\n",
    "        f\"[SOURCE: {flattened_df['source'].iloc[i]}]\\n{flattened_df['chunk'].iloc[i]}\"\n",
    "        for i in indices_set\n",
    "    ]\n",
    "\n",
    "    # Combine context and user question\n",
    "    context_text = \"\\n\\n\".join(context_chunks)\n",
    "    prompt = f\"Context:\\n{context_text}\\n\\nBased only on the provided context, answer this question: {user_input}\"\n",
    "\n",
    "    # Create message payload\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant helping a candidate prepare for job interviews. Only use the provided context (resume, job description, interview tips, company info) to answer. Do not make up facts or experiences. If the answer cannot be inferred from context, respond with 'I dont have enough information to answer that.'. Try to be brief.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # use chat completion to generate a response\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=os.getenv('AZURE_OPENAI_DEPLOYMENT'),\n",
    "        temperature=0.3,\n",
    "        max_tokens=200,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a11cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the job description and my skills, I am a good fit for this role at Avanade for several reasons:\\n\\n1. **Systems Experience**: My background in building solutions using Large Language Models (LLMs) aligns with the technical requirements of the role. I have a practical understanding of prompt engineering, semantic search, tool usage, and orchestrated multi-agent workflows, which are crucial for the job.\\n\\n2. **Communication & Leadership**: I have demonstrated the ability to engage both technical and non-technical stakeholders effectively. This is evidenced by my experience leading architecture reviews and representing AI strategy in cross-functional conversations, which matches the job's need for someone who can navigate complex stakeholder landscapes.\\n\\n3. **Continuous Learning**: My strong curiosity and drive to stay current with the latest in AI research, technologies, and tools make me well-suited to contribute to Avanade's culture of innovation and continuous improvement.\\n\\n4. **Personal Characteristics**: The traits described as beneficial for success in this role,\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"why are you a good fit for this job?\"\n",
    "chatbot(user_input,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
